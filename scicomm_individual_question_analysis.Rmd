---
title: 'Individual Question Analysis: Sci-Comm Identity (Q2 on Survey)'
output:
  html_document:
    df_print: paged
---
Goal: To look at each individual question in survey question 2, where students were asked to express their agreement with science communication identity statements.  

```{r data setup, message=FALSE, warning=FALSE, include=FALSE}
library(broom)
library(tidyverse)
library(ggsignif)

#import functions, themes 
source("~/Documents/teaching/science_communication_data/github/sci-comm-data-analysis/themes_functions_scicomm.R")

#import joined data file
sc<-read.csv(file="~/Desktop/data/scicomm_data_joined.csv")  
```

```{r scicomm score and long form data, include=FALSE, warning = TRUE, message = TRUE}
#importing code for scicomm score and long form data from other .Rmd file 

#scicomm score 
sc<-sc %>%
   replace(is.na(.), 0) %>% #change to 0 for ease of math 
   mutate(scicommscore_begin = rowSums(.[23:45]), 
          scicommscore_final = rowSums(.[66:88]), 
          scicommscore_change = scicommscore_final - scicommscore_begin) %>% #add question groupings 
   mutate(community_begin = rowSums(select_(.,"impact_begin", "impact2_begin", "convey_begin", "importscicomm_begin")), 
          community_final = rowSums(select_(.,"impact_final", "impact2_final", "convey_final", "importscicomm_final")), 
          confidence_begin = rowSums(select_(.,"explanation_begin", "explanation2_begin", "selfconf_begin","tellstory_begin")), 
          confidence_final = rowSums(select_(.,"explanation_final", "explanation2_final", "selfconf_final","tellstory_final")),
          identity_begin = rowSums(select_(.,"commpeer_begin", "commlay_begin", "idscicomm_begin", "commpeer2_begin", "commlay2_begin","idphysiocomm_begin")),
          identity_final = rowSums(select_(.,"commpeer_final", "commlay_final", "idscicomm_final", "commpeer2_final", "commlay2_final","idphysiocomm_final")),
          toolsable_begin = rowSums(select_(.,"tools_begin", "accurateinfo_begin", "assessaccuracy_begin")),
          toolsable_final = rowSums(select_(.,"tools_final", "accurateinfo_final", "assessaccuracy_final")))

sc[sc == 0] <- NA  #return 0 to NA

#further mutates to create a change score for the question groupings
sc<- sc %>%
  mutate(community_change = community_final - community_begin, 
         confidence_change = confidence_final - confidence_begin,
         identity_change = identity_final - identity_begin,
         toolsable_change = toolsable_final - toolsable_begin)

```

```{r long dataset, echo = FALSE, warning = FALSE, message = FALSE}
#scid dataset creation (long form of dataset with scicomm data only)
scid<-sc %>% 
 select(id, group,scientist_begin:tellstory_begin, scientist_final:tellstory_final, scicommscore_begin:toolsable_change)%>%
  gather(question, value, scientist_begin:toolsable_change)%>%
  separate(col = question, into = c("question", "survey"), sep = "_") 
#minor clean up 
scid$survey<-as.factor(scid$survey) #as factor
scid$question<-as.factor(scid$question)
```
###T-tests and plots: 
I ran a basic t-test for each question comparing the mean post-survey scores between the treatment and the control group. I then filtered this set of t-tests for any questions that returned a p-value < 0.06. 
The following questions returned: 

```{r t-tests with tidyverse, echo= FALSE, warning = FALSE, message = FALSE}
#using broom and dplyr to run multiple t-tests using the final survey scores for each question 
#does final score sig. differ between control and treatment group?

qgroupings<-c("community", "confidence", "identity", "toolsable") #qgrouping levels for filtering

scid %>% 
  filter(survey =="final")%>% #exclude change data for now 
  filter(!(question %in% qgroupings))%>%
  nest(-question) %>%  #run model on each level of question
  mutate(fit = map(data, ~ t.test(value ~ group, data = .)), #t-test formula 
         results = map(fit, glance)) %>% #broom functions
  unnest(results) %>% 
  filter(p.value <0.06) #filter results above by those with p less than 0.06


#returns the same values as the by-hand way, so success! 
```

Below are graphs showing the means and confidence intervals for these 3 questions: 

```{r ggplot loop, echo=FALSE, warning = FALSE, message = FALSE}
#dplyr loop that generates summary statistics and iterates through plots from above levels 

tplots<- scid %>% 
  filter(survey!="change", question == c("commlay2","tools","importscicomm")) %>%
  group_by(question, group, survey) %>% 
  summarise(smean = mean(value, na.rm = TRUE),  #summary statistics for each Q
            ssd = sd(value, na.rm = TRUE),
            count = n()) %>%
  mutate(se = ssd / sqrt(count),
         lower_ci = lower_ci(smean, se, count),
         upper_ci = upper_ci(smean, se, count)) %>%
  group_by(question) %>%
  do(plots=ggplot(data=.) +   #now create a graph FOR EACH of the above questions 
  aes(x=as.factor(group), y= as.numeric(smean), fill=survey) + 
  geom_bar(stat="identity", position = position_dodge(), color = "black")+ 
  geom_errorbar(aes(ymax=upper_ci,ymin=lower_ci),position=position_dodge(0.9), width=0.7)+
  ylim(0,10)+
  labs(x="Survey", y="Identity score")+
  scale_fill_manual(labels = c("Pre", "Post"), values = c("gray", "lightblue")) + 
  ggtitle(unique(.$question)))

#tplots$plots #view plots! 

tplots$plots[[1]] + ggtitle("I can communicate physiological concepts to a lay person") + plot_design
tplots$plots[[2]] + ggtitle("Communicating scientific knowledge to the public \n is an important aspect of being a science student") + plot_design
tplots$plots[[3]] + ggtitle("I have the tools needed to communicate scientific ideas") + plot_design

```

###Score differences within "question groupings"
Arik and I talked about assessing the survey score differences across different groupings of questions. 
Previously, I looked at overall score difference across the entire 2nd question (see previous reports).
Above, we looked at each question individually, comparing the final survey scores between the control and treatment groups with t-tests. 
Here, I'll compare cumulative scores across the following question groupings in question 2: _Note:_ Question groupings were assigned _a priori_ before analyses were performed.   

*  __Community Impact__  (max score: 40 pts)  
    + "I can make an impact in my community with my command of scientific ideas"  
    + "I can make an impact in my community with my command of physiological ideas"  
    + "Scientists should be able to convey interesting stories when sharing their research findings"    
    + "Communicating scientific knowledge to the public is an important aspect of being a science student"  

*  __Science Communication Identity__  (max score: 60 pts)  
    _May be split into "Science" and "Physiology" communication sub-groups_
    + "I can communicate scientific concept to another student in my class"  
    + "I can communicate scientific concept to a lay person"  
    + "I am a science communicator"    
    + "I can communicate physiological concepts to another student in my class"    
    + "I can communicate physiological concepts to a lay person"  
    + "I am a physiological communicator"  
    
*  __Tools and Abilities__  (max score: 30 pts)  
    + "I have the tools needed to communicate scientific ideas"  
    + "I know where to find accurate scientific information "  
    + "I know how to assess the accuracy and validity of scientific information "    

*  __Confidence in Abilities__  (max score: 30 pts)  
    + "I have self confidence when speaking "  
    + "I can tell an interesting story when discussing science "  
    + "My explanations of scientific concepts are clear and concise "   
    + "My explanations of physiological concepts are clear and concise"

Interestingly, the t-tests comparing the control group final scores versus the treatment group final survey scores are all non-significant (p > 0.1). Graphs below, however, imply that there may be significant differences between pre and post survey scores in the treatment group for "Confidence in Abilities" and "Science Communication Identity".  


```{r Q groupings, echo=FALSE, warning = FALSE, message = FALSE}

#t-tests for qgroupings
qgroup_across_ttest<- scid %>% 
  filter(survey =="final")%>% #exclude change data for now 
  filter(question %in% qgroupings)%>%
  nest(-question) %>%  #run model on each level of question
  mutate(fit = map(data, ~ t.test(value ~ group, data = .)), #t-test formula 
         results = map(fit, glance)) %>% #broom functions
  unnest(results) %>%  #no results have a p-value < 0.10
  arrange(p.value) %>% #list results in order of p-value (ascending)
  select(-data, - fit) #get rid of list variables for writing to csv 

qgroup_across_ttest 

qgroup_plots<- scid %>% 
  filter(survey!="change") %>% 
  filter(question %in% qgroupings) %>%
  group_by(question, group, survey) %>% 
  summarise(smean = mean(value, na.rm = TRUE),  #summary statistics for each Q
            ssd = sd(value, na.rm = TRUE),
            count = n()) %>%
  mutate(se = ssd / sqrt(count),
         lower_ci = lower_ci(smean, se, count),
         upper_ci = upper_ci(smean, se, count)) %>%
  group_by(question) %>%
  do(plots=ggplot(data=.) +   #now create a graph FOR EACH of the above questions 
  aes(x=as.factor(group), y= as.numeric(smean), fill=survey) + 
  geom_bar(stat="identity", position = position_dodge(), color = "black")+ 
  geom_errorbar(aes(ymax=upper_ci,ymin=lower_ci),position=position_dodge(0.9), width=0.7)+
  labs(x="Survey", y="Identity score")+
  scale_fill_manual(labels = c("Pre", "Post"), values = c("gray", "lightblue")) + 
  ggtitle(unique(.$question)))


qgroup_plots$plots

#graph that has all question groups in one graph 
#ISSUE: community still does not work in this code 

scid %>% 
  filter(survey=="final") %>% 
  filter(question %in% qgroupings) %>%
  group_by(question, group) %>% 
  summarise(smean = mean(value, na.rm = TRUE),  #summary statistics for each Q
            ssd = sd(value, na.rm = TRUE),
            count = n()) %>%
  mutate(se = ssd / sqrt(count),
         lower_ci = lower_ci(smean, se, count),
         upper_ci = upper_ci(smean, se, count)) %>%
  group_by(question) %>%
  ggplot(aes(x=as.factor(question), y= as.numeric(smean), fill = group)) + 
  geom_bar(stat="identity", position = position_dodge(), color = "black")+ 
  geom_errorbar(aes(ymax=upper_ci,ymin=lower_ci),position=position_dodge(0.9), width=0.7)+
  annotate("text", x = 1, y = 30, label = "n.s.")+ #non-siginifcance labels 
  annotate("text", x = 2, y = 45, label = "n.s.")+
  annotate("text", x = 3, y = 25, label = "n.s.")+
  labs(x="Survey", y="Total score")+
  scale_fill_manual(name= "Group", labels = c("Control\n(n=40)", "Treatment\n(n=37)"), values = c("grey", "skyblue2"))+ 
  scale_x_discrete(name="Question Theme", labels=c( "Confidence", "Identity", "Tools & Abilities"))+
  ggtitle("Differences in Science Identity Final Survey Score Between-Groups")+
  theme_bw()

```

```{r qgroupings within-individuals}
#t-tests by groupings, for students who had both pre and post surveys (within individual changes)

qgroups_within_ttests <- scid %>% 
  filter(survey =="change")%>% 
  filter(question %in% qgroupings)%>%
  nest(-question) %>%  #run model on each level of question
  mutate(fit = map(data, ~ t.test(value ~ group, data = .)), #t-test formula 
         results = map(fit, glance)) %>% #broom functions
  unnest(results) %>%
  arrange(p.value) %>% #list in ascending order of p-value
  select(-data, - fit)
  
qgroups_within_ttests

#plots of change differences 
#?? why is community working now in this dataset??
qgroup_change_plots<- scid %>% 
  filter(survey=="change") %>% 
  filter(question %in% qgroupings) %>%
  group_by(question, group) %>% 
  summarise(smean = mean(value, na.rm = TRUE),  #summary statistics for each Q
            ssd = sd(value, na.rm = TRUE),
            count = n()) %>%
  mutate(se = ssd / sqrt(count),
         lower_ci = lower_ci(smean, se, count),
         upper_ci = upper_ci(smean, se, count)) %>%
  group_by(question) %>%
  do(plots=ggplot(data=.) +   #now create a graph FOR EACH of the above questions 
  aes(x=as.factor(group), y= as.numeric(smean), fill = group) + 
  geom_bar(stat="identity", position = position_dodge(), color = "black")+ 
  geom_errorbar(aes(ymax=upper_ci,ymin=lower_ci),position=position_dodge(0.9), width=0.7)+
  labs(x="Survey", y="Change in score")+
  scale_fill_manual(labels = c("Control", "Treatment"), values = c("blue", "orange")) + 
  ggtitle(unique(.$question)))

#graph with all question groupings in one graph 

scid %>% 
  filter(survey=="change") %>% 
  filter(question %in% qgroupings) %>%
  group_by(question, group) %>% 
  summarise(smean = mean(value, na.rm = TRUE),  #summary statistics for each Q
            ssd = sd(value, na.rm = TRUE),
            count = n()) %>%
  mutate(se = ssd / sqrt(count),
         lower_ci = lower_ci(smean, se, count),
         upper_ci = upper_ci(smean, se, count)) %>%
  group_by(question) %>%
  ggplot(aes(x=as.factor(question), y= as.numeric(smean), fill = group)) + 
  geom_bar(stat="identity", position = position_dodge(), color = "black")+ 
  geom_errorbar(aes(ymax=upper_ci,ymin=lower_ci),position=position_dodge(0.9), width=0.7)+
  geom_segment(aes(x=2.75, y=12, xend=3.25, yend=12))+ #significance bar for community
  annotate("text", x = 3, y = 12.25, label = "**")+
  geom_segment(aes(x=3.75, y=6, xend=4.25, yend=6))+ #significance bar for tools
  annotate("text", x = 4, y = 6.25, label = "**")+
  labs(x="Survey", y="Change in score")+
  scale_fill_manual(name= "Group", labels = c("Control\n(n=25)", "Treatment\n(n=22)"), values = c("skyblue2", "lightgoldenrod"))+ 
  scale_x_discrete(labels=c("Community", "Confidence", "Identity", "Tools & Abilities"))+
  ggtitle("Changes in Science Identity Score Within-Groups")+
  theme_bw()


#boxplots with individual points 
scid %>% 
  filter(survey=="change") %>% 
  filter(question %in% qgroupings) %>%
  group_by(question, group) %>% 
  ggplot(aes(x=as.factor(question), y= value, fill = group)) + 
  geom_point(aes(color = group), position = position_jitterdodge())+ 
  geom_boxplot(alpha = 0.3, outlier.shape = NA) + 
  geom_segment(aes(x=2.75, y=25, xend=3.25, yend=25))+ #significance bar for community
  annotate("text", x = 3, y = 25.25, label = "**")+
  geom_segment(aes(x=3.75, y=11, xend=4.25, yend=11))+ #significance bar for tools
  annotate("text", x = 4, y = 11.25, label = "**")+
  labs(x="Survey", y="Change in score")+
  scale_fill_manual(name= "Group", labels = c("Control\n(n=25)", "Treatment\n(n=22)"), values = c(c("grey", "skyblue2")))+ 
  scale_x_discrete(labels=c("Community", "Confidence", "Identity", "Tools & Abilities"))+
  scale_color_manual(values = c("grey", "skyblue2"))+
  ggtitle("Changes in Science Identity Score Within-Groups")+
  theme_bw()

```

```{r not sure what this is..., message=FALSE, warning=, include=FALSE}

#ISSUE FLAG: there are change scores for students that did not complete both begin and end scores (probably due to 0 and NA coding) so these may be throwing off statistics. 

#subset sc dataset to those that completed both pre and post survey 
prepost_only <- sc %>%
  filter(!is.na(startdate_begin)) %>%
  filter(!is.na(startdate_final))  #sanity check: sample size is 47

students_w_prepost <- prepost_only$id #vector containing ids from above dataset 

#use that list to then filter scid dataset 
prepost_only <-scid %>%
  filter(id %in% students_w_prepost) #will overwrite original prepost_only dataset to use 

  geom_line(position=position_dodge(0.9))+
  geom_point(position=position_dodge(0.9), size=3)
  
prepost_change_plots<- scid %>% 
  filter(survey!="change") %>% 
  filter(question %in% qgroupings) %>%
  group_by(question, group, survey) %>% 
  summarise(smean = mean(value, na.rm = TRUE),  #summary statistics for each Q
            ssd = sd(value, na.rm = TRUE),
            count = n()) %>%
  mutate(se = ssd / sqrt(count),
         lower_ci = lower_ci(smean, se, count),
         upper_ci = upper_ci(smean, se, count)) %>%
  group_by(question) %>%
  do(plots=ggplot(data=.) +   #now create a graph FOR EACH of the above questions 
  aes(x=as.factor(survey), y= as.numeric(smean), color = group, group = group) + 
  geom_line(position=position_dodge(0.9))+
  geom_point(position=position_dodge(0.9), size=3)+
  geom_errorbar(aes(ymax=upper_ci,ymin=lower_ci),position=position_dodge(0.9), width=0.7)+
  labs(x="Survey", y="Score")+
  scale_fill_manual(labels = c("Control", "Treatment"), values = c("blue", "orange")) + 
  ggtitle(unique(.$question))) 

prepost_change_plots$plots[[1]] + ggtitle ("Changes in Confidence in SciComm ability", subtitle= "Within-student change") +  theme_bw() 

prepost_change_plots$plots[[2]] + ggtitle ("Changes in Identity as a Science Communicator", subtitle= "Within-student change") + theme_bw() 

prepost_change_plots$plots[[3]] + ggtitle ("Changes in Assessment of SciComm Tools & Abilities", subtitle= "Within-student change") + theme_bw() 


#t-tests
prepost_only %>% 
  filter(survey =="change")%>% #exclude change data for now 
  filter(question %in% qgroupings)%>%
  nest(-question) %>%  #run model on each level of question
  mutate(fit = map(data, ~ t.test(value ~ group, data = .)), #t-test formula 
         results = map(fit, glance)) %>% #broom functions
  unnest(results)  #no results have a p-value < 0.10
```

###Assignment assessment questions. 
Questions 10 and 12 on the Qualtrics survey.  Each question should range from 1 to 7, 1 being strongly disagree and 7 being strongly agree.  

```{r assignment questions, echo=FALSE, message=FALSE, warning=FALSE}
#Q10 on the qualtrics survey are coded strangely, need to be scaled to interpretable numbers.
#Q10 ($assignment) ranges 18 - 24. Subtract 17 to make it range 1 - 7. 
sc$assignment <- (sc$assignment - 17) 

#Q12 ranges 4 - 10. Subtract 3 to make range 1- 7. 
sc$future_assgn <- (sc$future_assgn - 3) 

###PLOT

#likert labels for plots 

likert.labels <-c("Strongly Disagree", "Disagree", "Somewhat Disagree", "Neither agree nor disagree", "Somewhat Agree", "Agree", "Strongly Agree" )

#question labels for the facet_wrap labeller function 

q10q12<-c("The biweekly assignments were beneficial for my learning", "I would like to have exercises that are similar to the biweekly assignments in other courses")
names(q10q12) <- c("assignment","future_assgn")

#Q10 and Q12 in one plot using facet wrap 
sc %>%
  select(id, group, assignment, future_assgn) %>%
  tidyr::pivot_longer(assignment:future_assgn, names_to = "question", values_to = "score") %>%
  filter(!is.na(score)) %>%
  mutate(score = as.factor(score)) %>%
  group_by(group, question, score) %>%
  summarise(n = n ()) %>%
  ggplot(aes(x=as.numeric(score), y=n, fill = group )) + 
  geom_bar(stat = "identity", position = position_dodge(0.9), color = "black")+ 
  scale_fill_manual(name= "Group", labels = c("Control\n(n=40)", "Treatment\n(n=37)"), values = c("grey", "skyblue2")) + 
  scale_x_reverse(name = "Likert score", breaks = (7:1), labels = function(x) str_wrap(likert.labels, width = 10))+ 
  ylab("Count")+
  facet_wrap(~question, nrow = 2, labeller = labeller(question = q10q12)) + 
  theme_bw()

q10q12<-c("The biweekly assignments were beneficial for my learning", "I would like to have exercises that are similar to the biweekly assignments in other courses")
names(q10q12) <- c("assignment","future_assgn")
```

###Linear models: 
I also ran basic linear models for each question and filtered any covariates that had an effect that was statistically significant (p < 0.06). 
Linear model structure: `lm(score ~ survey*group)`.   
This returned 5 questions that had an effect of the final survey, but no interaction terms were statistically significant.   Need to do some stats readings to understand why this is the case, and if another model may be more appropriate.  

```{r tidyverse linear models, echo = FALSE, message = FALSE, warning = FALSE }
#linear models w/ summary statistics using tidyverse broom and dplyr packages

scid %>% 
  filter(survey!="change")%>% #exclude score change data for now 
  group_by(question) %>% 
  do(tidy(lm(value ~ survey*group, .))) %>% #(end pipe here and you will get all stats for all models)
  filter(term!="(Intercept)") %>%  #exclude intercept terms as not informative
  filter(p.value < 0.06) #what has a p-value less than 0.06?

#returns 5 questions that had an effect of the final survey, but no interaction terms were significant. 
```

```{r BY HAND (OLD WAY) t-tests p-values, eval=FALSE, message=FALSE, warning=TRUE, include=FALSE}
#t-test contrasts will be after the class and activity, so using final survey data only for t-tests
#filter dataset by final survey:
scid_end<- scid %>%
  filter(survey == "final")

#t-tests compare final survey score by group (treatment or control)
t_tests_post<-with(scid_end,
       by(scid_end, question,
          function(x) t.test(value ~ group, data=x)
       )
     )

#create a data table with all p-values for t-tests
pvals_post <- lapply(t_tests_post, function(x) x$p.value) #extracts p-values from the above t-tests list
pvals_post <- data.frame(matrix(unlist(pvals_post), nrow=length(pvals_post), byrow=T)) #create dataframe 
pvals_post$question<-as.factor(names(t_tests_post)) #extracts the names of each question in the t-test
colnames(pvals_post)<- c("pval", "question") #rename columns for interpretability
pvals_post$pval<-as.numeric(pvals_post$pval)
pvals_post<-pvals_post[order(pvals_post$pval),] #sorts data frame by p-value in ascending order

pvals_post %>%
  filter(pval< 0.06) #returns the questiosn that had a pvalue less than 0.06 
```

Resources used: 
https://stackoverflow.com/questions/30332752/how-to-perform-t-tests-for-each-level-of-a-factor-with-tapply
https://stackoverflow.com/questions/35194782/convert-output-from-multiple-t-tests-to-data-frame
https://stackoverflow.com/questions/4227223/convert-a-list-to-a-data-frame

https://www.r-bloggers.com/running-a-model-on-separate-groups/
Read this for understanding pre-post stats on linear models: https://m-clark.github.io/docs/mixedModels/anovamixed.html#between_groups_approach
http://varianceexplained.org/r/broom-intro/ #where to run do(linear models broom and dpylr)

Plot loops : https://stackoverflow.com/questions/29034863/apply-a-ggplot-function-per-group-with-dplyr-and-set-title-per-group

How to do rowSums in dplyr: https://stackoverflow.com/questions/41895432/mutating-column-in-dplyr-using-rowsums


